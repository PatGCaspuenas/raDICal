{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-scale (MS) CNN autoencoder\n",
    "## Author: Taichi Nakamura (Keio university, Japan)\n",
    "Taichi Nakamura provides no guarantees for this code.  Use as-is and for academic research use only; no commercial use allowed without permission. For citations, please use the reference below:  \n",
    "Ref: Taichi Nakamura, Kai Fukami, and Koji Fukagata, \"Convolutional neural network and long short-term memory based reduced order surrogate for minimal turbulent channel flow,\" Physics of Fluids, 2021.  \n",
    "The code is written for educational clarity and not for speed.  \n",
    "-- version 1: Jan 27, 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For making MS CNN-AE, the user has to install 'keras', 'numpy', 'pandas' and 'sklearn'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Add, Conv3D, MaxPooling3D, UpSampling3D, Reshape\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import ModelCheckpoint,EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridSetting = (34,66,34)\n",
    "\n",
    "datasetSerial = np.arange(100,1000100,100)\n",
    "datasetPrefix = './data_box/UVWP'\n",
    "\n",
    "u_all = np.zeros((len(datasetSerial),32,32,32))\n",
    "v_all = np.zeros((len(datasetSerial),32,32,32))\n",
    "w_all = np.zeros((len(datasetSerial),32,32,32))\n",
    "\n",
    "for i in tqdm(range(len(datasetSerial))):\n",
    "    name = datasetPrefix + '{0:07d}'.format(datasetSerial[i])\n",
    "    df = pd.read_csv(name, header=None, delim_whitespace=True)\n",
    "    dataset = df.values\n",
    "    BOX = dataset[:,:]\n",
    "\n",
    "    u_org = BOX[:,0].reshape(gridSetting,order='F')\n",
    "    v_org = BOX[:,1].reshape(gridSetting,order='F')\n",
    "    w_org = BOX[:,2].reshape(gridSetting,order='F')\n",
    "\n",
    "    u_all[i,:,:,:] = u_org[1:33,1:33,1:33]\n",
    "    v_all[i,:,:,:] = v_org[1:33,1:33,1:33]\n",
    "    w_all[i,:,:,:] = w_org[1:33,1:33,1:33]\n",
    "    \n",
    "u_mean = u_all.mean(axis=3).mean(axis=0).mean(axis=0)\n",
    "v_mean = v_all.mean(axis=3).mean(axis=0).mean(axis=0)\n",
    "w_mean = w_all.mean(axis=3).mean(axis=0).mean(axis=0)\n",
    "\n",
    "u_flc = np.zeros(u_all.shape)\n",
    "v_flc = np.zeros(v_all.shape)\n",
    "w_flc = np.zeros(w_all.shape)\n",
    "\n",
    "for j in tqdm(range(32)):\n",
    "    u_flc[:,:,j,:] = u_all[:,:,j,:] - u_mean[j]\n",
    "    v_flc[:,:,j,:] = v_all[:,:,j,:] - v_mean[j]\n",
    "    w_flc[:,:,j,:] = w_all[:,:,j,:] - w_mean[j]\n",
    "\n",
    "data_raw = np.zeros((len(datasetSerial),32,32,32,3)) #Training data\n",
    "data_raw[:,:,:,:,0] = u_flc\n",
    "data_raw[:,:,:,:,1] = v_flc\n",
    "data_raw[:,:,:,:,2] = w_flc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = Input(shape=(32,32,32,3))\n",
    "\n",
    "#Multi-scale model (Du et al., 2018)\n",
    "x1 = Conv3D(16, (3,3,3),activation='relu', padding='same')(input_img)\n",
    "x1 = Conv3D(8, (3,3,3),activation='relu', padding='same')(x1)\n",
    "x1 = MaxPooling3D((2,2,2),padding='same')(x1)\n",
    "x1 = Conv3D(16, (3,3,3),activation='relu', padding='same')(x1)\n",
    "x1 = Conv3D(8, (3,3,3),activation='relu', padding='same')(x1)\n",
    "x1 = MaxPooling3D((2,2,2),padding='same')(x1)\n",
    "x1 = Conv3D(3, (3,3,3),activation='tanh', padding='same')(x1)\n",
    "\n",
    "x2 = Conv3D(16, (5,5,5),activation='relu', padding='same')(input_img)\n",
    "x2 = Conv3D(8, (5,5,5),activation='relu', padding='same')(x2)\n",
    "x2 = MaxPooling3D((2,2,2),padding='same')(x2)\n",
    "x2 = Conv3D(16, (5,5,5),activation='relu', padding='same')(x2)\n",
    "x2 = Conv3D(8, (5,5,5),activation='relu', padding='same')(x2)\n",
    "x2 = MaxPooling3D((2,2,2),padding='same')(x2)\n",
    "x2 = Conv3D(3, (5,5,5),activation='tanh', padding='same')(x2)\n",
    "\n",
    "x3 = Conv3D(16, (7,7,7),activation='relu', padding='same')(input_img)\n",
    "x3 = Conv3D(8, (7,7,7),activation='relu', padding='same')(x3)\n",
    "x3 = MaxPooling3D((2,2,2),padding='same')(x3)\n",
    "x3 = Conv3D(16, (7,7,7),activation='relu', padding='same')(x3)\n",
    "x3 = Conv3D(8, (7,7,7),activation='relu', padding='same')(x3)\n",
    "x3 = MaxPooling3D((2,2,2),padding='same')(x3)\n",
    "x3 = Conv3D(3, (7,7,7),activation='tanh', padding='same')(x3)\n",
    "\n",
    "x = Add()([x1,x2,x3])\n",
    "x_lnt = Reshape((1536,))(x) # For LSTM training\n",
    "\n",
    "x = Reshape((8,8,8,3))(x_lnt)\n",
    "\n",
    "x1 = Conv3D(3, (3,3,3),activation='relu', padding='same')(x)\n",
    "x1 = UpSampling3D((2,2,2))(x1)\n",
    "x1 = Conv3D(8, (3,3,3),activation='relu', padding='same')(x1)\n",
    "x1 = Conv3D(16, (3,3,3),activation='relu', padding='same')(x1)\n",
    "x1 = UpSampling3D((2,2,2))(x1)\n",
    "x1 = Conv3D(8, (3,3,3),activation='relu', padding='same')(x1)\n",
    "x1 = Conv3D(16, (3,3,3),activation='relu', padding='same')(x1)\n",
    "\n",
    "x2 = Conv3D(3, (5,5,5),activation='relu', padding='same')(x)\n",
    "x2 = UpSampling3D((2,2,2))(x2)\n",
    "x2 = Conv3D(8, (5,5,5),activation='relu', padding='same')(x2)\n",
    "x2 = Conv3D(16, (5,5,5),activation='relu', padding='same')(x2)\n",
    "x2 = UpSampling3D((2,2,2))(x2)\n",
    "x2 = Conv3D(8, (5,5,5),activation='relu', padding='same')(x2)\n",
    "x2 = Conv3D(16, (5,5,5),activation='relu', padding='same')(x2)\n",
    "\n",
    "x3 = Conv3D(3, (7,7,7),activation='relu', padding='same')(x)\n",
    "x3 = UpSampling3D((2,2,2))(x3)\n",
    "x3 = Conv3D(8, (7,7,7),activation='relu', padding='same')(x3)\n",
    "x3 = Conv3D(16, (7,7,7),activation='relu', padding='same')(x3)\n",
    "x3 = UpSampling3D((2,2,2))(x3)\n",
    "x3 = Conv3D(8, (7,7,7),activation='relu', padding='same')(x3)\n",
    "x3 = Conv3D(16, (7,7,7),activation='relu', padding='same')(x3)\n",
    "\n",
    "x = Add()([x1,x2,x3])\n",
    "x_final = Conv3D(3, (3,3,3),padding='same')(x)\n",
    "autoencoder = Model(input_img, x_final)\n",
    "autoencoder.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learn parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data_raw, data_raw, test_size=0.3, random_state=None)\n",
    "model_cb=ModelCheckpoint('./Model.hdf5', monitor='val_loss',save_best_only=True,verbose=1)\n",
    "early_cb=EarlyStopping(monitor='val_loss', patience=50,verbose=1)\n",
    "cb = [model_cb, early_cb]\n",
    "history = dscms.fit(X_train,y_train,nb_epoch=5000,batch_size=128,verbose=1,callbacks=cb,shuffle=True,validation_data=[X_test, y_test])\n",
    "df_results = pd.DataFrame(history.history)\n",
    "df_results['epoch'] = history.epoch\n",
    "df_results.to_csv(path_or_buf='./Model.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
