{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Long short-term memory (LSTM)\n",
    "## Author: Taichi Nakamura (Keio university, Japan)\n",
    "Taichi Nakamura provides no guarantees for this code.  Use as-is and for academic research use only; no commercial use allowed without permission. For citations, please use the reference below:  \n",
    "Ref: Taichi Nakamura, Kai Fukami, and Koji Fukagata, \"Convolutional neural network and long short-term memory based reduced order surrogate for minimal turbulent channel flow,\" Physics of Fluids, 2021.  \n",
    "The code is written for educational clarity and not for speed.  \n",
    "-- version 1: Jan 27, 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For making LSTM, the user has to install 'keras', 'numpy', 'pandas' and 'sklearn'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.layers import Input, Add\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import ModelCheckpoint,EarlyStopping\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridSetting = (34,66,34)\n",
    "\n",
    "datasetSerial = np.arange(100,1000100,100)\n",
    "datasetPrefix = './data_box/UVWP'\n",
    "\n",
    "u_all = np.zeros((len(datasetSerial),32,32,32))\n",
    "v_all = np.zeros((len(datasetSerial),32,32,32))\n",
    "w_all = np.zeros((len(datasetSerial),32,32,32))\n",
    "\n",
    "for i in tqdm(range(len(datasetSerial))):\n",
    "    name = datasetPrefix + '{0:07d}'.format(datasetSerial[i])\n",
    "    df = pd.read_csv(name, header=None, delim_whitespace=True)\n",
    "    dataset = df.values\n",
    "    BOX = dataset[:,:]\n",
    "\n",
    "    u_org = BOX[:,0].reshape(gridSetting,order='F')\n",
    "    v_org = BOX[:,1].reshape(gridSetting,order='F')\n",
    "    w_org = BOX[:,2].reshape(gridSetting,order='F')\n",
    "\n",
    "    u_all[i,:,:,:] = u_org[1:33,1:33,1:33]\n",
    "    v_all[i,:,:,:] = v_org[1:33,1:33,1:33]\n",
    "    w_all[i,:,:,:] = w_org[1:33,1:33,1:33]\n",
    "    \n",
    "u_mean = u_all.mean(axis=3).mean(axis=0).mean(axis=0)\n",
    "v_mean = v_all.mean(axis=3).mean(axis=0).mean(axis=0)\n",
    "w_mean = w_all.mean(axis=3).mean(axis=0).mean(axis=0)\n",
    "\n",
    "u_flc = np.zeros(u_all.shape)\n",
    "v_flc = np.zeros(v_all.shape)\n",
    "w_flc = np.zeros(w_all.shape)\n",
    "\n",
    "for j in tqdm(range(32)):\n",
    "    u_flc[:,:,j,:] = u_all[:,:,j,:] - u_mean[j]\n",
    "    v_flc[:,:,j,:] = v_all[:,:,j,:] - v_mean[j]\n",
    "    w_flc[:,:,j,:] = w_all[:,:,j,:] - w_mean[j]\n",
    "\n",
    "data_raw = np.zeros((len(datasetSerial),32,32,32,3))\n",
    "data_raw[:,:,:,:,0] = u_flc\n",
    "data_raw[:,:,:,:,1] = v_flc\n",
    "data_raw[:,:,:,:,2] = w_flc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtain latent vectors ${\\eta}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('./Model.hdf5') # Load CNN-AE\n",
    "layer_name = 'reshape_1'\n",
    "model_latent = Model(inputs=model.input, outputs=model.get_layer(layer_name).output) # Define CNN encoder part\n",
    "latent_vec = model_latent.predict(data_raw) # (# of dataset, latent vector size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make training dataset for LSTM  \n",
    "input data: {$\\eta^{(n-5)\\Delta t},\\eta^{(n-4)\\Delta t},\\eta^{(n-3)\\Delta t},\\eta^{(n-2)\\Delta t},\\eta^{(n-1)\\Delta t}$}  \n",
    "shape: (# of dataset, 5, latent vector size)  \n",
    "label: {$\\eta^{(n-4)\\Delta t},\\eta^{(n-3)\\Delta t},\\eta^{(n-2)\\Delta t},\\eta^{(n-1)\\Delta t},\\eta^{n\\Delta t}$}  \n",
    "shape: (# of dataset, 5, latent vector size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(data_in):\n",
    "\n",
    "    data, target = [], [] # Input data, label\n",
    "    maxlen = 5 # The number of timestep required for prediction\n",
    "\n",
    "    for i in range(len(data_in[:,0])-maxlen):\n",
    "        data.append(data_in[i:i + maxlen,:])\n",
    "        target.append(data_in[(i+1):(i+maxlen+1),:])\n",
    "\n",
    "    re_data = np.array(data).reshape(len(data), maxlen, 4*4*4*3,order='F')\n",
    "    re_target = np.array(target).reshape(len(data), maxlen, 4*4*4*3,order='F')\n",
    "\n",
    "    return re_data, re_target\n",
    "\n",
    "data_input, data_label = make_dataset(latent_vec) # Input data, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constrct LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = Input(shape=(None,192))\n",
    "\n",
    "x1 = LSTM(192,return_sequences=True,activation='tanh',batch_input_shape=(None, None, 192))(input_img)\n",
    "x1 = LSTM(192,return_sequences=True,activation='linear')(x1)\n",
    "\n",
    "x2 = LSTM(288,return_sequences=True,activation='tanh',batch_input_shape=(None, None, 192))(input_img)\n",
    "x2 = LSTM(192,return_sequences=True,activation='linear')(x2)\n",
    "\n",
    "x3 = LSTM(384,return_sequences=True,activation='tanh',batch_input_shape=(None, None, 192))(input_img)\n",
    "x3 = LSTM(192,return_sequences=True,activation='linear')(x3)\n",
    "\n",
    "x4 = LSTM(480,return_sequences=True,activation='tanh',batch_input_shape=(None, None, 192))(input_img)\n",
    "x4 = LSTM(192,return_sequences=True,activation='linear')(x4)\n",
    "\n",
    "x5 = LSTM(576,return_sequences=True,activation='tanh',batch_input_shape=(None, None, 192))(input_img)\n",
    "x5 = LSTM(192,return_sequences=True,activation='linear')(x5)\n",
    "\n",
    "x6 = LSTM(672,return_sequences=True,activation='tanh',batch_input_shape=(None, None, 192))(input_img)\n",
    "x6 = LSTM(192,return_sequences=True,activation='linear')(x6)\n",
    "\n",
    "x7 = LSTM(768,return_sequences=True,activation='tanh',batch_input_shape=(None, None, 192))(input_img)\n",
    "x7 = LSTM(192,return_sequences=True,activation='linear')(x7)\n",
    "\n",
    "x = Add()([x1,x2,x3,x4,x5,x6,x7])\n",
    "x_final = (Activation('tanh'))(x)\n",
    "\n",
    "model_LSTM = Model(input_img, x_final)\n",
    "model_LSTM.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learn parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cb=ModelCheckpoint('./Model_LSTM.hdf5', monitor='val_loss',save_best_only=True,verbose=1)\n",
    "early_cb=EarlyStopping(monitor='val_loss', patience=50,verbose=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_input, data_label, test_size=0.3, random_state=True)\n",
    "cb = [model_cb, early_cb]\n",
    "history = dscms.fit(X_train, y_train,\n",
    "          batch_size=16,\n",
    "          epochs=1000,\n",
    "          verbose = 1,\n",
    "          validation_data=[X_test,y_test],\n",
    "          callbacks=cb,\n",
    "          shuffle=True\n",
    "          )\n",
    "df_results = pd.DataFrame(history.history)\n",
    "df_results['epoch'] = history.epoch\n",
    "df_results.to_csv(path_or_buf='./Model_LSTM.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
